{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "## Step:\n",
    "\n",
    "1. Define Hypothesis Function f(x)\n",
    "2. Define Loss Functions $l(y, f(x))$\n",
    "3. minimize the loss function (empritical) $$ \\min \\sum_n l(y, f(x))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linear regression\n",
    "\n",
    "- under GM condition\n",
    "\n",
    "> where $$ y = wx + \\epsilon \\;\\;\\mbox{ and } \\;\\;\\epsilon \\sim N(0,\\sigma^2) $$\n",
    ">\n",
    "> Thus $$ y \\sim N(wx, \\sigma^2) $$\n",
    ">\n",
    "> Therefore $$ p(y|x ; w) = {1\\over \\sqrt{2\\pi} \\sigma} \\exp( -{ (y-wx)^2 \\over 2\\sigma^2 } ) $$\n",
    ">\n",
    "> It turn out tha when we try to maximize the likelihood function above, which is same as to maximize the log-likelihood function, it give the same answer as minimizing out loss function below \n",
    ">\n",
    "> Note that  : the final $w^*$ is not depend on $\\sigma$\n",
    "\n",
    "- loss function\n",
    "\n",
    ">$$ J(\\theta) = {1\\over 2} \\sum^n_i(h_\\theta (x^{(i)}) - y^{(i)})^2 $$\n",
    "\n",
    "- LMS algorithm (train)\n",
    "\n",
    ">$$ \\theta_j = \\theta_j - \\alpha ( {d J(\\theta) \\over d\\theta_j } ) $$\n",
    "> where \n",
    ">$$ {d J(\\theta) \\over d\\theta_j } = \\sum_i^n (h_\\theta(x^{(i)}) - y^{(i)})x^{(i)}_j $$\n",
    "\n",
    "- Mathematical Matrix Solution\n",
    "> $$ \\theta^* = (X^TX)^{-1} X^T y $$\n",
    "\n",
    "## Locally weighted linear regression\n",
    "\n",
    "> Assume that there is sufficient training data, and try to make the choice of features less critical\n",
    "\n",
    "> #### \" Prevent overfitting and underfitting \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "- LMS algorithm update same as above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logistic\n",
    "\n",
    "- ##### Goal : find a hyperplan can universaly separte two calsses\n",
    "\n",
    "> linear $\\to$ perceptron $\\to$ logistic\n",
    "\n",
    "- loss function\n",
    "\n",
    "> $$ J(\\theta) = \\sum^n_i \\sum^C_cI_{h_\\theta (x^{(i)}) != c}(x^{(i)})p(y^{(i)} = c|x^{(i)})) $$\n",
    "> $$ = \\sum^n_i (1 - p(y^{(i)} = h_\\theta(x^{(i)}) | x^{(i)})) $$\n",
    "> turn out, it is same as\n",
    "> $$ max_c p(y=c | x) \\;\\; \\forall x $$\n",
    "\n",
    "- LMS algorithm (same as linear )\n",
    "\n",
    ">$$ \\theta_j = \\theta_j - \\alpha ( {d l(\\theta) \\over d\\theta_j } ) $$\n",
    "> where $l(\\theta)$ is a log likelihood function\n",
    ">$$ {d l(\\theta) \\over d\\theta_j } = \\sum_i^n (y^{(i)}-h_\\theta(x^{(i)}))x^{(i)}_j $$\n",
    ">> General form for logistic and linear\n",
    ">>\n",
    ">> $$ w_j = w_j + \\alpha ( y^{(i)}-h_\\theta(x^{(i)}))x^{(i)}_j $$\n",
    "> where\n",
    "> $$ h_\\theta(x) = {1 \\over 1+e^{-\\theta^Tx}} $$\n",
    "\n",
    "- Theoritical Way revisit\n",
    "\n",
    "> ### Generalized Linear Models (GLM)\n",
    "\n",
    ">> 1. $y|x, \\theta \\sim $ exponential family\n",
    ">> 2. Hypothesis function $h(x) = E[y|x, \\theta] $\n",
    ">> 3. $\\eta = \\theta x $ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------Above Are all discriminative model--------------------------------\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Model ( Generative Learning Algorithm )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discriminative v.s Generative \n",
    "\n",
    "> Discriminative  : p(y|x) \n",
    ">\n",
    "> Generative : p(x|y)p(y) joint probability \n",
    ">\n",
    "> ex. [ need to be filled ]\n",
    "\n",
    "- Basic Idea\n",
    "\n",
    "> $$ \\arg \\max_y p(y|x) = \\arg \\max_y {p(x|y)p(y) \\over p(x) } = \\arg \\max_y p(x|y)p(y)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian discriminant analysis (Generative model) \n",
    "\n",
    "\n",
    "## LDA\n",
    "\n",
    "\n",
    "- The multivariate normal distribution\n",
    "\n",
    "> [ need to be filled ]\n",
    "\n",
    "- Hypothesis\n",
    "\n",
    "> $$ y \\sim \\mbox{ Bernoulli }(\\phi) $$\n",
    ">\n",
    "> $$ x|y = 0 \\sim N(\\mu_0, \\Sigma) \\;\\;\\;\\;  \\bf{\\mbox{ ( multivariate Gaussian ) }}$$\n",
    ">\n",
    "> $$ x|y = 1 \\sim N(\\mu_2, \\Sigma) \\;\\;\\;\\;  \\bf{\\mbox{ ( multivariate Gaussian ) }}$$\n",
    ">\n",
    "> ##### $\\Sigma$ Covariance Matrix are same for both x | y = 0 and x | y = 1\n",
    ">\n",
    "> Then we can implement into probability distribution, and try to find prior $\\phi^*\\;,\\;\\mu_0$... that maximize log-likelihood function \n",
    ">\n",
    "> [ need to be filled ]\n",
    ">\n",
    ">\n",
    "> ###### Turn out that $p(y|x,\\Sigma, \\mu_0 , \\dots)$ can be expressend in the form same as logistic!!!!\n",
    "\n",
    "- Logistic v.s. GDA\n",
    "\n",
    "> ###### GDA has stronger assumption than logistic\n",
    ">> such that p(x|y) is multivariate gaussian then p(y|x) necessarily follows a logistic function is True\n",
    ">>\n",
    ">> But p(y|x) is logistic function does'nt imply that p(x|y) is multivariate gaussian\n",
    "\n",
    "> ##### Therefore, if p(x|y) assumption is correct then GDA is better but if it's wrong it turn out that logistic regression will do better\n",
    "\n",
    "> ###### GDA is data efficient, require less training data to learn well, but Logistic is robust to deviations from modeling assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Generative model) \n",
    "\n",
    "- Basic Idea ( NB Assumption ):\n",
    "\n",
    "> $x_i$'s are conditionally independent given y\n",
    "\n",
    "\n",
    "- ##### QDA\n",
    "\n",
    "> which means that $\\Sigma$ matrix is diagonal\n",
    ">\n",
    "> and x | y = 0 and x | y = 1 have different covariance matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "- revisit perceptron\n",
    "\n",
    "- Basic Idea:\n",
    "\n",
    "> if $y(\\theta^T x) >> 0$ , then we are very confident that $y=1$ in this classifier\n",
    ">\n",
    "> then we want to push data x as far as possible from boundary\n",
    ">\n",
    "> turn out that we want to find a large geometric margin \n",
    "\n",
    "- Functional and geometric margins\n",
    "\n",
    "> functional margin :  $ \\min_i y(\\theta^Tx + b) $\n",
    ">\n",
    "> Since we can scale $\\theta$ and b to be sufficient large, then we can make the functional margin arbitrarily large without really changing anything meaningful.\n",
    "\n",
    "> geometric margin : $$\\min_i y({\\theta^T \\over || \\theta || } x + {b \\over || \\theta || } ) $$\n",
    "> \n",
    "> Notice that if $||\\theta|| = 1$, functional and geometric margin are same\n",
    ">\n",
    "> Then, our goal is trying to maximize the smallest of geometric margins on the training examples\n",
    "\n",
    "### Optimization Problem\n",
    "\n",
    "> ###### First : \n",
    "> find $w$ ( geometric margin = functional margin  )\n",
    ">\n",
    "> $$ \\max \\gamma  $$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } y^{(i)}(w^Tx^{(i)} + b) \\geq \\gamma \\;\\;\\; \\forall \\; i $$\n",
    ">\n",
    "> $$ || w || = 1 $$\n",
    ">\n",
    "> $|| w || = 1 $ is no-convex conxtraint\n",
    "\n",
    "\n",
    "> ###### Second : \n",
    "> $$ \\max {\\hat \\gamma \\over || w||}  $$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } y^{(i)}(w^Tx^{(i)} + b) \\geq \\hat\\gamma \\;\\;\\; \\forall \\; i $$\n",
    ">\n",
    ">\n",
    "> However, ${ \\gamma \\over || w||} $ is (no-convex) nasty objective function\n",
    "\n",
    "\n",
    "> ###### Third : \n",
    "> Knowing that we can rescale w, b without changin boundary\n",
    "> \n",
    "> Let's scale w,b such that $\\min_i y^{(i)}(w^Tx^{(i)} + b) = 1 $\n",
    ">\n",
    "> Turn out $\\hat \\gamma = 1$\n",
    ">\n",
    "> $$ \\max {1 \\over || w ||}  $$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } y^{(i)}(w^Tx^{(i)} + b) \\geq 1 \\;\\;\\; \\forall \\; i $$\n",
    ">\n",
    ">\n",
    "> We still don't like $ {1 \\over || w ||} $, \n",
    "> \n",
    "> but since maximize  $ {1 \\over || w ||} $ is same as minimize $ ||w||^2$\n",
    ">\n",
    "> We get\n",
    ">\n",
    "> ##### Fourth\n",
    "> $$ \\min {1\\over 2} || w||^2  $$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } y^{(i)}(w^Tx^{(i)} + b) \\geq 1 \\;\\;\\; \\forall \\; i $$\n",
    ">\n",
    "> which is a potimization problem with a convex quadratic objective and linear constraints\n",
    "\n",
    "## Lagrange Duality\n",
    "\n",
    "> Under KKT conditions, primal problem is same as dual problem\n",
    ">\n",
    "> [ need to be filled ]\n",
    "\n",
    "\n",
    "> Thus we can rewrite problem above as\n",
    ">\n",
    "> $$ \\min_w \\max_{\\alpha} {1\\over 2} || w||^2  - \\sum^n \\alpha_i[ y^{(i)}(w^Tx^{(i)} + b) - 1]$$\n",
    ">\n",
    "> So if we minize the function respect to w first, we will get $$ w = \\sum^n a_i y^{(i)}x^{(i)} $$\n",
    ">\n",
    "> plug into the Lagrangian and get\n",
    ">\n",
    "> $$ \\max_{\\alpha} \\sum^n \\alpha_i - {1\\over 2} \\sum^n_{i,j} y^{(i)}y^{(j)} \\alpha_i \\alpha_j (x^{(i)})^T x^{(j)} $$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } \\alpha_i \\geq 0 $$\n",
    ">\n",
    "> $$ \\sum a_iy^{(i)} = 0 $$ (KKT condition)\n",
    "\n",
    "> #### Turn out we only care about $\\alpha_i \\neq 0 $, since $w^*$ is a function of $\\alpha, y, x$ = $\\sum^n_i \\alpha_i y^{(i)} x^{(i)} $\n",
    "\n",
    "## Final Result (SVM why SVM)\n",
    "\n",
    "After training, for a new test x\n",
    "\n",
    "$$ w^Tx + b = ( \\sum^n_i \\alpha_i y^{(i)} x^{(i)} )^T x +b =  \\sum^n_i \\alpha_i y^{(i)} <x^{(i)}, x> + b $$\n",
    "\n",
    "will only be a inner products between x and suppor vectors( $\\alpha_i > 0 $ ).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization \n",
    "\n",
    "- prevent overfitting to outliers, consider $\\ell 1$ regularization\n",
    "- which make sense, since we only want some $\\xi_i$ to be active\n",
    "> $$ \\min {1\\over 2} || w||^2  + C \\sum_i \\xi_i$$\n",
    ">\n",
    "> $$ \\mbox{ s.t. } y^{(i)}(w^Tx^{(i)} + b) \\geq 1 - \\xi_i \\;\\;\\; \\forall \\; i $$\n",
    ">\n",
    "> Turn out that \n",
    "> $$ a_i = 0 \\to \\; y^{(i)}(w^Tx^{(i)} + b) \\geq 1 $$\n",
    "> $$ a_i = C \\to \\; y^{(i)}(w^Tx^{(i)} + b) \\leq 1 $$\n",
    "> $$ 0 < a_i < C \\to \\; y^{(i)}(w^Tx^{(i)} + b) = 1 $$\n",
    "\n",
    "\n",
    "## Update Algorighm (SMO , Coordinate ascent )\n",
    "\n",
    "- Fixed some $\\alpha_i$ and maximized the objective function for some unfixed $\\alpha_i$. Note that if we fix $\\alpha_i \\;\\; \\forall i = 2, \\dots , n$, we can't make any progress for $\\alpha_1$ since $\\sum^n \\alpha_i y^{(i)} = 0$ \n",
    "\n",
    "> $$\\hat\\alpha_i = \\arg\\max_{\\hat\\alpha_i} W(\\alpha_1\\dots ) = \\arg\\max_{\\hat\\alpha_i} \\sum \\alpha_i - {1\\over 2} \\sum y^{(i)}y^{(j)} \\alpha_i \\alpha_j < x^{(i)} , x^{(j)} > $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM-Algorithm\n",
    "- [ need to be filled ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Newton's Method\n",
    "\n",
    "$$ \\theta = \\theta - { f(\\theta)\\over f'(\\theta)} $$\n",
    "\n",
    "- Typically provides faster convergence tha gradient descent and requires many fewer iterations to get very close to the minimum. One iteration of Newton's can bemore expensive than one iteration of gradient descent, since it requires finding and inverting an nxn Hessian. But so long as n is not too large, it's usually much faster overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
